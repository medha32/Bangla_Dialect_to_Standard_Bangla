{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Team Information**\n",
    "* Team Name: Neuralsight\n",
    "* Members: Utpal Barua, Nuzhat Tabassum Medha\n",
    "* Model: [https://huggingface.co/utpal07/wav2vec2-bangla-finetuned-xlarge](https://huggingface.co/utpal07/wav2vec2-bangla-finetuned-xlarge)\n",
    "* Libraries: Transformers, Datasets, Evaluate, Librosa, Soundfile, Audiomentations, PyTorch\n",
    "* Dataset: Custom Bangla audio dataset from /kaggle/input/shobdotori, including training audio files organized by dialects (e.g., Rajshahi) and annotations in CSV format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 1: Environment Setup & Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-17T11:59:38.708949Z",
     "iopub.status.busy": "2025-11-17T11:59:38.708696Z",
     "iopub.status.idle": "2025-11-17T11:59:57.303670Z",
     "shell.execute_reply": "2025-11-17T11:59:57.302676Z",
     "shell.execute_reply.started": "2025-11-17T11:59:38.708925Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pyarrow 16.1.0\n",
      "Uninstalling pyarrow-16.1.0:\n",
      "  Successfully uninstalled pyarrow-16.1.0\n",
      "Found existing installation: protobuf 6.33.1\n",
      "Uninstalling protobuf-6.33.1:\n",
      "  Successfully uninstalled protobuf-6.33.1\n",
      "\u001b[33mWARNING: Skipping google-cloud-bigquery-storage as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m213.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m300.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.7/260.7 kB\u001b[0m \u001b[31m339.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "audiomentations 0.27.0 requires librosa<0.10.0,>0.7.2, but you have librosa 0.11.0 which is incompatible.\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.3 which is incompatible.\n",
      "a2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 4.25.3 which is incompatible.\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.3 which is incompatible.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.3 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.3.0)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.14.3)\n",
      "Requirement already satisfied: audiomentations==0.27.0 in /usr/local/lib/python3.11/dist-packages (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.27.0) (1.26.4)\n",
      "Collecting librosa<0.10.0,>0.7.2 (from audiomentations==0.27.0)\n",
      "  Using cached librosa-0.9.2-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: scipy<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.27.0) (1.15.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.11/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (4.4.2)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (0.4.3)\n",
      "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.11/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.11/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (25.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.0->audiomentations==0.27.0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.0->audiomentations==0.27.0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.0->audiomentations==0.27.0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.0->audiomentations==0.27.0) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.0->audiomentations==0.27.0) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.0->audiomentations==0.27.0) (2.4.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.45.1->librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (2.32.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (2.0.0)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.13.0->audiomentations==0.27.0) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.13.0->audiomentations==0.27.0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.13.0->audiomentations==0.27.0) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.13.0->audiomentations==0.27.0) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.13.0->audiomentations==0.27.0) (2024.2.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (2.23)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.13.0->audiomentations==0.27.0) (2024.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations==0.27.0) (2025.10.5)\n",
      "Using cached librosa-0.9.2-py3-none-any.whl (214 kB)\n",
      "Installing collected packages: librosa\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.11.0\n",
      "    Uninstalling librosa-0.11.0:\n",
      "      Successfully uninstalled librosa-0.11.0\n",
      "Successfully installed librosa-0.9.2\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (4.25.3)\n",
      "Collecting protobuf\n",
      "  Using cached protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Using cached protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.33.1 which is incompatible.\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.1 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.1 which is incompatible.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.1 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-6.33.1\n"
     ]
    }
   ],
   "source": [
    "# Install required packages with specific versions\n",
    "!pip uninstall -y pyarrow protobuf google-cloud-bigquery-storage\n",
    "!pip install -U pyarrow==16.1.0 protobuf==4.25.3 datasets==2.21.0 \\\n",
    "    evaluate==0.4.3 librosa soundfile jiwer --no-cache-dir --quiet\n",
    "!pip install jiwer\n",
    "!pip install audiomentations==0.27.0\n",
    "!pip install --upgrade protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Import transformers components\n",
    "from transformers import pipeline, WhisperProcessor, WhisperForConditionalGeneration\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor\n",
    "from transformers import TrainingArguments,Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Import ML utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import evaluate\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:08.094422Z",
     "iopub.status.busy": "2025-11-17T12:00:08.093773Z",
     "iopub.status.idle": "2025-11-17T12:00:08.098236Z",
     "shell.execute_reply": "2025-11-17T12:00:08.097689Z",
     "shell.execute_reply.started": "2025-11-17T12:00:08.094400Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nTraining on device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 2: Disable W&B and Unnecessary Warnings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:08.099492Z",
     "iopub.status.busy": "2025-11-17T12:00:08.099201Z",
     "iopub.status.idle": "2025-11-17T12:00:08.120847Z",
     "shell.execute_reply": "2025-11-17T12:00:08.120126Z",
     "shell.execute_reply.started": "2025-11-17T12:00:08.099447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Disable Weights & Biases\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "os.environ[\"WANDB_API_KEY\"] = \"dummy\"\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:08.121872Z",
     "iopub.status.busy": "2025-11-17T12:00:08.121620Z",
     "iopub.status.idle": "2025-11-17T12:00:09.542738Z",
     "shell.execute_reply": "2025-11-17T12:00:09.541723Z",
     "shell.execute_reply.started": "2025-11-17T12:00:08.121850Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mwandb in modules: False\n"
     ]
    }
   ],
   "source": [
    "# Uninstall wandb completely\n",
    "!pip uninstall -y wandb\n",
    "\n",
    "# Verify wandb is not imported\n",
    "import sys\n",
    "print(\"wandb in modules:\", \"wandb\" in sys.modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 3: Verify Package Versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:09.544431Z",
     "iopub.status.busy": "2025-11-17T12:00:09.544048Z",
     "iopub.status.idle": "2025-11-17T12:00:09.549837Z",
     "shell.execute_reply": "2025-11-17T12:00:09.549134Z",
     "shell.execute_reply.started": "2025-11-17T12:00:09.544403Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PACKAGE VERSIONS\n",
      "Accelerate:    1.9.0\n",
      "Protobuf:      6.33.1\n",
      "Transformers:  4.53.3\n",
      "Datasets:      2.21.0\n",
      "PEFT:          0.16.0\n"
     ]
    }
   ],
   "source": [
    "import google.protobuf\n",
    "import transformers\n",
    "import datasets\n",
    "import peft\n",
    "import accelerate\n",
    "\n",
    "print(\"PACKAGE VERSIONS\")\n",
    "print(f\"Accelerate:    {accelerate.__version__}\")\n",
    "print(f\"Protobuf:      {google.protobuf.__version__}\")\n",
    "print(f\"Transformers:  {transformers.__version__}\")\n",
    "print(f\"Datasets:      {datasets.__version__}\")\n",
    "print(f\"PEFT:          {peft.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 4: Install Audio Augmentation Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:09.550856Z",
     "iopub.status.busy": "2025-11-17T12:00:09.550627Z",
     "iopub.status.idle": "2025-11-17T12:00:09.581607Z",
     "shell.execute_reply": "2025-11-17T12:00:09.581041Z",
     "shell.execute_reply.started": "2025-11-17T12:00:09.550840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, TimeStretch\n",
    "\n",
    "# Define augmentation pipeline\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.4),\n",
    "    PitchShift(min_semitones=-2, max_semitones=2, p=0.4),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.3)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 5: Configuration Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:09.582533Z",
     "iopub.status.busy": "2025-11-17T12:00:09.582251Z",
     "iopub.status.idle": "2025-11-17T12:00:09.586810Z",
     "shell.execute_reply": "2025-11-17T12:00:09.586206Z",
     "shell.execute_reply.started": "2025-11-17T12:00:09.582510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# SECTION 5: Configuration Class\n",
    "\n",
    "class Config:\n",
    "    model_name = \"utpal07/wav2vec2-bangla-finetuned-large\"\n",
    "    \n",
    "    # Audio processing\n",
    "    sampling_rate = 16000\n",
    "    max_duration = 10.0\n",
    "    max_length = int(sampling_rate * max_duration)\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    batch_size = 2\n",
    "    gradient_accumulation_steps = 8\n",
    "    learning_rate = 5e-5\n",
    "    num_epochs = 30\n",
    "    weight_decay = 0.01\n",
    "    warmup_steps = 500\n",
    "    \n",
    "    # Logging and checkpointing\n",
    "    logging_steps = 100\n",
    "    save_total_limit = 2\n",
    "    save_strategy = \"epoch\"\n",
    "    eval_strategy = \"epoch\"\n",
    "    load_best_model_at_end = True\n",
    "    metric_for_best_model = \"wer\"\n",
    "    greater_is_better = False\n",
    "    fp16 = True\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 6: Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:09.587879Z",
     "iopub.status.busy": "2025-11-17T12:00:09.587659Z",
     "iopub.status.idle": "2025-11-17T12:00:09.603723Z",
     "shell.execute_reply": "2025-11-17T12:00:09.603132Z",
     "shell.execute_reply.started": "2025-11-17T12:00:09.587858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# SECTION 6: Utility Functions\n",
    "\n",
    "def safe_normalize(audio):\n",
    "    max_val = np.max(np.abs(audio))\n",
    "    if max_val > 0:\n",
    "        return audio / max_val\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:09.604910Z",
     "iopub.status.busy": "2025-11-17T12:00:09.604646Z",
     "iopub.status.idle": "2025-11-17T12:00:09.622092Z",
     "shell.execute_reply": "2025-11-17T12:00:09.621522Z",
     "shell.execute_reply.started": "2025-11-17T12:00:09.604888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Load all training data from dialect folders\n",
    "\n",
    "def load_dataset(base_path):\n",
    "    \n",
    "    audio_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    train_path = os.path.join(base_path, \"Train\")\n",
    "    annotation_path = os.path.join(base_path, \"Train_annotation\")\n",
    "    \n",
    "    # Load annotations from CSV files\n",
    "    for csv_file in os.listdir(annotation_path):\n",
    "        if csv_file.endswith('.csv'):\n",
    "            dialect = csv_file.replace('.csv', '')\n",
    "            csv_path = os.path.join(annotation_path, csv_file)\n",
    "            df = pd.read_csv(csv_path)\n",
    "            \n",
    "            for _, row in df.iterrows():\n",
    "                audio_file = row['audio']\n",
    "                text = row['text']\n",
    "                \n",
    "                # Construct full audio path\n",
    "                dialect_folder = os.path.join(train_path, dialect)\n",
    "                audio_path = os.path.join(dialect_folder, audio_file)\n",
    "                \n",
    "                if os.path.exists(audio_path):\n",
    "                    audio_paths.append(audio_path)\n",
    "                    labels.append(text)\n",
    "    \n",
    "    return audio_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:09.622850Z",
     "iopub.status.busy": "2025-11-17T12:00:09.622690Z",
     "iopub.status.idle": "2025-11-17T12:00:09.644053Z",
     "shell.execute_reply": "2025-11-17T12:00:09.643503Z",
     "shell.execute_reply.started": "2025-11-17T12:00:09.622837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Split data into train and validation sets\n",
    "\n",
    "def prepare_data_for_training(audio_paths, labels, test_size=0.1):\n",
    "    \n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        audio_paths, \n",
    "        labels, \n",
    "        test_size=test_size, \n",
    "        random_state=42, \n",
    "        shuffle=True\n",
    "    )\n",
    "    return train_paths, val_paths, train_labels, val_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 7: Custom Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:09.645119Z",
     "iopub.status.busy": "2025-11-17T12:00:09.644876Z",
     "iopub.status.idle": "2025-11-17T12:00:09.660625Z",
     "shell.execute_reply": "2025-11-17T12:00:09.660092Z",
     "shell.execute_reply.started": "2025-11-17T12:00:09.645099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BanglaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, audio_paths, labels, processor, max_duration=10.0, \n",
    "                 sampling_rate=16000, augment_audio=False):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.labels = labels\n",
    "        self.processor = processor\n",
    "        self.max_duration = max_duration\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.augment_audio = augment_audio\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.audio_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load audio file\n",
    "        speech_array, sr = sf.read(audio_path)\n",
    "        \n",
    "        # Resample if necessary\n",
    "        if sr != self.sampling_rate:\n",
    "            speech_array = librosa.resample(\n",
    "                speech_array, \n",
    "                orig_sr=sr, \n",
    "                target_sr=self.sampling_rate\n",
    "            )\n",
    "        \n",
    "        # Normalize audio\n",
    "        speech_array = safe_normalize(speech_array)\n",
    "        \n",
    "        # Apply augmentation (only for training)\n",
    "        if self.augment_audio:\n",
    "            speech_array = augment(\n",
    "                samples=speech_array, \n",
    "                sample_rate=self.sampling_rate\n",
    "            )\n",
    "        \n",
    "        # Encode labels\n",
    "        if isinstance(label, str) and len(label.strip()) > 0:\n",
    "            labels_ids = self.processor.tokenizer(label).input_ids\n",
    "        else:\n",
    "            labels_ids = [self.processor.tokenizer.pad_token_id]\n",
    "        \n",
    "        # Process audio into model input\n",
    "        inputs = self.processor(\n",
    "            speech_array,\n",
    "            sampling_rate=self.sampling_rate,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            max_length=int(self.max_duration * self.sampling_rate),\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_values\": inputs.input_values[0],\n",
    "            \"attention_mask\": inputs.attention_mask[0],\n",
    "            \"labels\": torch.tensor(labels_ids, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 8: Data Collator for CTC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:09.663739Z",
     "iopub.status.busy": "2025-11-17T12:00:09.663464Z",
     "iopub.status.idle": "2025-11-17T12:00:09.684835Z",
     "shell.execute_reply": "2025-11-17T12:00:09.684314Z",
     "shell.execute_reply.started": "2025-11-17T12:00:09.663725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DataCollatorCTCManual:\n",
    "    \n",
    "    def __init__(self, processor, padding_value=0.0, label_padding_value=-100):\n",
    "        self.processor = processor\n",
    "        self.padding_value = padding_value\n",
    "        self.label_padding_value = label_padding_value\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        # Extract input values and labels\n",
    "        input_values = [torch.tensor(x[\"input_values\"]) for x in batch]\n",
    "        labels = [torch.tensor(x[\"labels\"]) for x in batch]\n",
    "        \n",
    "        # Pad sequences to max length in batch\n",
    "        input_values_padded = pad_sequence(\n",
    "            input_values, \n",
    "            batch_first=True, \n",
    "            padding_value=self.padding_value\n",
    "        )\n",
    "        labels_padded = pad_sequence(\n",
    "            labels, \n",
    "            batch_first=True, \n",
    "            padding_value=self.label_padding_value\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_values\": input_values_padded, \n",
    "            \"labels\": labels_padded\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 9: Metrics Computation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:09.685593Z",
     "iopub.status.busy": "2025-11-17T12:00:09.685399Z",
     "iopub.status.idle": "2025-11-17T12:00:09.704232Z",
     "shell.execute_reply": "2025-11-17T12:00:09.703523Z",
     "shell.execute_reply.started": "2025-11-17T12:00:09.685579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \n",
    "    wer_metric = evaluate.load(\"wer\")\n",
    "    \n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = pred_logits.argmax(-1)\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "    \n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 10: Load and Prepare Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:09.705212Z",
     "iopub.status.busy": "2025-11-17T12:00:09.705013Z",
     "iopub.status.idle": "2025-11-17T12:00:15.003274Z",
     "shell.execute_reply": "2025-11-17T12:00:15.002602Z",
     "shell.execute_reply.started": "2025-11-17T12:00:09.705191Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET STATISTICS\n",
      "Total samples:     3350\n",
      "Sample audio path: /kaggle/input/shobdotori/Train/Rajshahi/male_rajshahi_2.wav\n",
      "Sample label:      তুমি কি নতুন বই পড়তে চাও?\n",
      "\n",
      "Training samples:   3015\n",
      "Validation samples: 335\n"
     ]
    }
   ],
   "source": [
    "# Load and Prepare Data\n",
    "\n",
    "# Set base path\n",
    "base_path = \"/kaggle/input/shobdotori\"\n",
    "\n",
    "# Load dataset\n",
    "audio_paths, labels = load_dataset(base_path)\n",
    "\n",
    "print(\"DATASET STATISTICS\")\n",
    "print(f\"Total samples:     {len(audio_paths)}\")\n",
    "print(f\"Sample audio path: {audio_paths[0]}\")\n",
    "print(f\"Sample label:      {labels[0]}\")\n",
    "\n",
    "# Split into train and validation\n",
    "train_paths, val_paths, train_labels, val_labels = prepare_data_for_training(\n",
    "    audio_paths, labels, test_size=0.1\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples:   {len(train_paths)}\")\n",
    "print(f\"Validation samples: {len(val_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 11: Initialize Model and Processor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:15.005168Z",
     "iopub.status.busy": "2025-11-17T12:00:15.004200Z",
     "iopub.status.idle": "2025-11-17T12:00:15.736327Z",
     "shell.execute_reply": "2025-11-17T12:00:15.735740Z",
     "shell.execute_reply.started": "2025-11-17T12:00:15.005143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load tokenizer and feature extractor\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(config.model_name)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(config.model_name)\n",
    "\n",
    "processor = Wav2Vec2Processor(\n",
    "    tokenizer=tokenizer,\n",
    "    feature_extractor=feature_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:15.737337Z",
     "iopub.status.busy": "2025-11-17T12:00:15.737068Z",
     "iopub.status.idle": "2025-11-17T12:00:16.389456Z",
     "shell.execute_reply": "2025-11-17T12:00:16.388881Z",
     "shell.execute_reply.started": "2025-11-17T12:00:15.737313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    config.model_name,\n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.1,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer),\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:16.390718Z",
     "iopub.status.busy": "2025-11-17T12:00:16.390318Z",
     "iopub.status.idle": "2025-11-17T12:00:16.394582Z",
     "shell.execute_reply": "2025-11-17T12:00:16.393847Z",
     "shell.execute_reply.started": "2025-11-17T12:00:16.390584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Freeze feature encoder (only fine-tune upper layers)\n",
    "model.freeze_feature_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 12: Create Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:16.395561Z",
     "iopub.status.busy": "2025-11-17T12:00:16.395304Z",
     "iopub.status.idle": "2025-11-17T12:00:16.412529Z",
     "shell.execute_reply": "2025-11-17T12:00:16.411769Z",
     "shell.execute_reply.started": "2025-11-17T12:00:16.395533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create training dataset (with augmentation)\n",
    "train_dataset = BanglaDataset(\n",
    "    train_paths, \n",
    "    train_labels, \n",
    "    processor,\n",
    "    augment_audio=True\n",
    ")\n",
    "\n",
    "# Create validation dataset (no augmentation)\n",
    "val_dataset = BanglaDataset(\n",
    "    val_paths, \n",
    "    val_labels, \n",
    "    processor,\n",
    "    augment_audio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:16.413403Z",
     "iopub.status.busy": "2025-11-17T12:00:16.413218Z",
     "iopub.status.idle": "2025-11-17T12:00:16.428757Z",
     "shell.execute_reply": "2025-11-17T12:00:16.428168Z",
     "shell.execute_reply.started": "2025-11-17T12:00:16.413387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize data collator\n",
    "data_collator = DataCollatorCTCManual(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 13: Training Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:16.429761Z",
     "iopub.status.busy": "2025-11-17T12:00:16.429515Z",
     "iopub.status.idle": "2025-11-17T12:00:16.476726Z",
     "shell.execute_reply": "2025-11-17T12:00:16.476122Z",
     "shell.execute_reply.started": "2025-11-17T12:00:16.429736Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./wav2vec2-bangla-checkpoints\",\n",
    "    per_device_train_batch_size=config.batch_size,\n",
    "    per_device_eval_batch_size=config.batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    learning_rate=config.learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    "    warmup_steps=config.warmup_steps,\n",
    "    num_train_epochs=config.num_epochs,\n",
    "    logging_steps=config.logging_steps,\n",
    "    fp16=config.fp16,\n",
    "    save_strategy=config.save_strategy,\n",
    "    eval_strategy=config.eval_strategy,\n",
    "    save_total_limit=config.save_total_limit,\n",
    "    load_best_model_at_end=config.load_best_model_at_end,\n",
    "    metric_for_best_model=config.metric_for_best_model,\n",
    "    greater_is_better=config.greater_is_better,\n",
    "    report_to=None,\n",
    "    group_by_length=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 14: Initialize Trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:16.477689Z",
     "iopub.status.busy": "2025-11-17T12:00:16.477427Z",
     "iopub.status.idle": "2025-11-17T12:00:17.230123Z",
     "shell.execute_reply": "2025-11-17T12:00:17.229300Z",
     "shell.execute_reply.started": "2025-11-17T12:00:16.477665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# SECTION 14: Initialize Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 15: Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T12:00:17.231115Z",
     "iopub.status.busy": "2025-11-17T12:00:17.230907Z",
     "iopub.status.idle": "2025-11-17T16:46:44.935024Z",
     "shell.execute_reply": "2025-11-17T16:46:44.934293Z",
     "shell.execute_reply.started": "2025-11-17T12:00:17.231093Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2850' max='2850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2850/2850 4:44:21, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.617800</td>\n",
       "      <td>0.329793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.774100</td>\n",
       "      <td>0.642722</td>\n",
       "      <td>0.332588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.698500</td>\n",
       "      <td>0.652963</td>\n",
       "      <td>0.333147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.649000</td>\n",
       "      <td>0.645762</td>\n",
       "      <td>0.330911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.642800</td>\n",
       "      <td>0.633509</td>\n",
       "      <td>0.333706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.618400</td>\n",
       "      <td>0.632305</td>\n",
       "      <td>0.330911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.586900</td>\n",
       "      <td>0.623879</td>\n",
       "      <td>0.338178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.559200</td>\n",
       "      <td>0.649194</td>\n",
       "      <td>0.334824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.552700</td>\n",
       "      <td>0.631729</td>\n",
       "      <td>0.335942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.532100</td>\n",
       "      <td>0.640110</td>\n",
       "      <td>0.330911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.530900</td>\n",
       "      <td>0.621989</td>\n",
       "      <td>0.332588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.500900</td>\n",
       "      <td>0.625209</td>\n",
       "      <td>0.331470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.476000</td>\n",
       "      <td>0.633633</td>\n",
       "      <td>0.328675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.641159</td>\n",
       "      <td>0.330352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.497700</td>\n",
       "      <td>0.633124</td>\n",
       "      <td>0.326439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.468900</td>\n",
       "      <td>0.633795</td>\n",
       "      <td>0.329793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.455100</td>\n",
       "      <td>0.637791</td>\n",
       "      <td>0.326439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.444500</td>\n",
       "      <td>0.631498</td>\n",
       "      <td>0.325321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.449100</td>\n",
       "      <td>0.622860</td>\n",
       "      <td>0.327557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.438200</td>\n",
       "      <td>0.630520</td>\n",
       "      <td>0.328675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.438200</td>\n",
       "      <td>0.619115</td>\n",
       "      <td>0.327557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.436700</td>\n",
       "      <td>0.610957</td>\n",
       "      <td>0.331470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.423400</td>\n",
       "      <td>0.613989</td>\n",
       "      <td>0.328675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.417900</td>\n",
       "      <td>0.637558</td>\n",
       "      <td>0.333706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>0.620307</td>\n",
       "      <td>0.330911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>0.627701</td>\n",
       "      <td>0.330911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.402700</td>\n",
       "      <td>0.622703</td>\n",
       "      <td>0.329793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.613775</td>\n",
       "      <td>0.326998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.390400</td>\n",
       "      <td>0.640335</td>\n",
       "      <td>0.330352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.619467</td>\n",
       "      <td>0.329234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c2d6fe4e2a4165a249e8ec4cae7338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2850, training_loss=0.5012007723356549, metrics={'train_runtime': 17072.6299, 'train_samples_per_second': 5.298, 'train_steps_per_second': 0.167, 'total_flos': 1.1396695447827616e+19, 'train_loss': 0.5012007723356549, 'epoch': 30.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **SECTION 16: Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T16:46:44.936241Z",
     "iopub.status.busy": "2025-11-17T16:46:44.935878Z",
     "iopub.status.idle": "2025-11-17T16:46:47.202377Z",
     "shell.execute_reply": "2025-11-17T16:46:47.201720Z",
     "shell.execute_reply.started": "2025-11-17T16:46:44.936216Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved to /kaggle/working/wav2vec2-bangla-finetuned\n"
     ]
    }
   ],
   "source": [
    "# Save fine-tuned model\n",
    "model_save_path = \"/kaggle/working/wav2vec2-bangla-finetuned\"\n",
    "trainer.save_model(model_save_path)\n",
    "processor.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"\\nModel saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 17: Evaluate Model (Validation Set)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T16:46:47.203411Z",
     "iopub.status.busy": "2025-11-17T16:46:47.203176Z",
     "iopub.status.idle": "2025-11-17T16:47:21.734442Z",
     "shell.execute_reply": "2025-11-17T16:47:21.733664Z",
     "shell.execute_reply.started": "2025-11-17T16:46:47.203384Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Levenshtein\n",
      "  Downloading levenshtein-0.27.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from Levenshtein) (3.14.3)\n",
      "Downloading levenshtein-0.27.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/153.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Levenshtein\n",
      "Successfully installed Levenshtein-0.27.3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION RESULTS\n",
      "Normalized Levenshtein Similarity: 0.9048\n"
     ]
    }
   ],
   "source": [
    "!pip install Levenshtein\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "# Get predictions on validation set\n",
    "predictions = trainer.predict(val_dataset)\n",
    "pred_ids = np.argmax(predictions.predictions, axis=-1)\n",
    "pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "\n",
    "# Decode labels\n",
    "label_ids = predictions.label_ids\n",
    "label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "# Calculate normalized Levenshtein similarity\n",
    "similarities = []\n",
    "for p, r in zip(pred_str, label_str):\n",
    "    dist = Levenshtein.distance(p, r)\n",
    "    max_len = max(len(p), len(r))\n",
    "    sim = 1 - dist / max_len if max_len > 0 else 1.0\n",
    "    similarities.append(sim)\n",
    "\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(f\"Normalized Levenshtein Similarity: {np.mean(similarities):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 18: Generate Test Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T16:54:19.533223Z",
     "iopub.status.busy": "2025-11-17T16:54:19.532629Z",
     "iopub.status.idle": "2025-11-17T16:54:57.851063Z",
     "shell.execute_reply": "2025-11-17T16:54:57.850215Z",
     "shell.execute_reply.started": "2025-11-17T16:54:19.533201Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf21afa345549258708d596415a9221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing Test Set:   0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load saved model for inference\n",
    "model_path = \"/kaggle/working/wav2vec2-bangla-finetuned\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_path)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_path).to(\"cuda\")\n",
    "\n",
    "\n",
    "def load_and_prepare_audio(audio_path, sampling_rate=16000):\n",
    "    audio, sr = sf.read(audio_path)\n",
    "    \n",
    "    # Convert stereo to mono if needed\n",
    "    if len(audio.shape) > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    \n",
    "    # Resample if necessary\n",
    "    if sr != sampling_rate:\n",
    "        audio = librosa.resample(audio, orig_sr=sr, target_sr=sampling_rate)\n",
    "    \n",
    "    # Normalize\n",
    "    max_val = np.max(np.abs(audio))\n",
    "    return audio / max_val if max_val > 0 else np.zeros_like(audio)\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    audio_input = load_and_prepare_audio(audio_path)\n",
    "    inputs = processor(\n",
    "        audio_input, \n",
    "        sampling_rate=16000, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(\"cuda\")).logits\n",
    "    \n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(pred_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    return transcription.strip()\n",
    "\n",
    "\n",
    "# Process test set\n",
    "test_dir = os.path.join(base_path, \"Test\")\n",
    "test_files = sorted([f for f in os.listdir(test_dir) if f.endswith(\".wav\")])\n",
    "\n",
    "predictions = []\n",
    "for test_file in tqdm(test_files, desc=\"Transcribing Test Set\"):\n",
    "    audio_path = os.path.join(test_dir, test_file)\n",
    "    text = transcribe_audio(audio_path)\n",
    "    predictions.append({\"audio\": test_file, \"text\": text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SECTION 19: Save Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T16:54:57.852369Z",
     "iopub.status.busy": "2025-11-17T16:54:57.852139Z",
     "iopub.status.idle": "2025-11-17T16:54:57.873261Z",
     "shell.execute_reply": "2025-11-17T16:54:57.872483Z",
     "shell.execute_reply.started": "2025-11-17T16:54:57.852351Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Submission saved to /kaggle/working/finalsubmission.csv\n",
      " Total predictions: 450\n"
     ]
    }
   ],
   "source": [
    "# Save predictions to CSV\n",
    "save_path = \"/kaggle/working/finalsubmission.csv\"\n",
    "pd.DataFrame(predictions).to_csv(save_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\" Submission saved to {save_path}\")\n",
    "print(f\" Total predictions: {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14372637,
     "sourceId": 119724,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
